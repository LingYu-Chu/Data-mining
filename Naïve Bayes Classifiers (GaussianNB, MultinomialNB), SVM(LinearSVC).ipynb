{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53940 entries, 0 to 53939\n",
      "Data columns (total 27 columns):\n",
      "Unnamed: 0        53940 non-null int64\n",
      "carat             53940 non-null float64\n",
      "cut_Fair          53940 non-null int64\n",
      "cut_Good          53940 non-null int64\n",
      "cut_Ideal         53940 non-null int64\n",
      "cut_Premium       53940 non-null int64\n",
      "cut_Very Good     53940 non-null int64\n",
      "color_D           53940 non-null int64\n",
      "color_E           53940 non-null int64\n",
      "color_F           53940 non-null int64\n",
      "color_G           53940 non-null int64\n",
      "color_H           53940 non-null int64\n",
      "color_I           53940 non-null int64\n",
      "color_J           53940 non-null int64\n",
      "clarity_I1        53940 non-null int64\n",
      "clarity_IF        53940 non-null int64\n",
      "clarity_SI1       53940 non-null int64\n",
      "clarity_SI2       53940 non-null int64\n",
      "clarity_VS1       53940 non-null int64\n",
      "clarity_VS2       53940 non-null int64\n",
      "clarity_VVS1      53940 non-null int64\n",
      "clarity_VVS2      53940 non-null int64\n",
      "cut               53940 non-null int64\n",
      "color             53940 non-null int64\n",
      "clarity           53940 non-null int64\n",
      "priceperpoint     53940 non-null int64\n",
      "carat_discrete    53940 non-null int64\n",
      "dtypes: float64(1), int64(26)\n",
      "memory usage: 11.1 MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "data=pd.read_csv(\"diamonds_data.csv\")\n",
    "data.info()\n",
    "\n",
    "#count value\n",
    "#data[\"z\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>carat</th>\n",
       "      <th>cut_Fair</th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>color_D</th>\n",
       "      <th>color_E</th>\n",
       "      <th>color_F</th>\n",
       "      <th>...</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>priceperpoint</th>\n",
       "      <th>carat_discrete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  carat  cut_Fair  cut_Good  cut_Ideal  cut_Premium  \\\n",
       "0           0   0.23         0         0          1            0   \n",
       "1           1   0.21         0         0          0            1   \n",
       "2           2   0.23         0         1          0            0   \n",
       "\n",
       "   cut_Very Good  color_D  color_E  color_F       ...        clarity_SI2  \\\n",
       "0              0        0        1        0       ...                  1   \n",
       "1              0        0        1        0       ...                  0   \n",
       "2              0        0        1        0       ...                  0   \n",
       "\n",
       "   clarity_VS1  clarity_VS2  clarity_VVS1  clarity_VVS2  cut  color  clarity  \\\n",
       "0            0            0             0             0    1      2        7   \n",
       "1            0            0             0             0    2      2        6   \n",
       "2            1            0             0             0    4      2        4   \n",
       "\n",
       "   priceperpoint  carat_discrete  \n",
       "0              1               1  \n",
       "1              1               1  \n",
       "2              1               1  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut_Fair</th>\n",
       "      <th>cut_Good</th>\n",
       "      <th>cut_Ideal</th>\n",
       "      <th>cut_Premium</th>\n",
       "      <th>cut_Very Good</th>\n",
       "      <th>color_D</th>\n",
       "      <th>color_E</th>\n",
       "      <th>color_F</th>\n",
       "      <th>color_G</th>\n",
       "      <th>...</th>\n",
       "      <th>clarity_SI2</th>\n",
       "      <th>clarity_VS1</th>\n",
       "      <th>clarity_VS2</th>\n",
       "      <th>clarity_VVS1</th>\n",
       "      <th>clarity_VVS2</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>priceperpoint</th>\n",
       "      <th>carat_discrete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   carat  cut_Fair  cut_Good  cut_Ideal  cut_Premium  cut_Very Good  color_D  \\\n",
       "0   0.23         0         0          1            0              0        0   \n",
       "1   0.21         0         0          0            1              0        0   \n",
       "2   0.23         0         1          0            0              0        0   \n",
       "\n",
       "   color_E  color_F  color_G       ...        clarity_SI2  clarity_VS1  \\\n",
       "0        1        0        0       ...                  1            0   \n",
       "1        1        0        0       ...                  0            0   \n",
       "2        1        0        0       ...                  0            1   \n",
       "\n",
       "   clarity_VS2  clarity_VVS1  clarity_VVS2  cut  color  clarity  \\\n",
       "0            0             0             0    1      2        7   \n",
       "1            0             0             0    2      2        6   \n",
       "2            0             0             0    4      2        4   \n",
       "\n",
       "   priceperpoint  carat_discrete  \n",
       "0              1               1  \n",
       "1              1               1  \n",
       "2              1               1  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop(\n",
    "data.columns[0],axis=1)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    7000\n",
      "3    7000\n",
      "2    7000\n",
      "1    7000\n",
      "Name: priceperpoint, dtype: int64\n",
      "training \n",
      " 1    5968\n",
      "2    5953\n",
      "4    5947\n",
      "3    5932\n",
      "Name: priceperpoint, dtype: int64\n",
      "testing \n",
      " 3    1068\n",
      "4    1053\n",
      "2    1047\n",
      "1    1032\n",
      "Name: priceperpoint, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "#cut data set into train and target data\n",
    "from sklearn.model_selection import train_test_split\n",
    "sampled_data=pd.concat([data[data['priceperpoint']==4].sample(7000),data[data['priceperpoint']==3].sample(7000),data[data['priceperpoint']==2].sample(7000),data[data['priceperpoint']==1].sample(7000)],ignore_index=True)\n",
    "\n",
    "print(sampled_data['priceperpoint'].value_counts())\n",
    "X=sampled_data.drop(['priceperpoint'], axis=1)\n",
    "y=sampled_data['priceperpoint']\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.15, random_state=0, stratify=None)\n",
    "print(\"training \\n\",y_train.value_counts())\n",
    "print(\"testing \\n\",y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# å…¨éƒ¨ç‰¹å¾µä¸‹åŽ»è·‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data accuracy: 69.78\n",
      "[[969  52  11   0]\n",
      " [383 443 211  10]\n",
      " [  0 186 730 152]\n",
      " [  1  39 260 753]]\n",
      "test data accuracy: 68.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.94      0.81      1032\n",
      "           2       0.62      0.42      0.50      1047\n",
      "           3       0.60      0.68      0.64      1068\n",
      "           4       0.82      0.72      0.77      1053\n",
      "\n",
      "    accuracy                           0.69      4200\n",
      "   macro avg       0.69      0.69      0.68      4200\n",
      "weighted avg       0.69      0.69      0.68      4200\n",
      "\n",
      "precision: 0.688841568105017 \n",
      "recall: 0.6892857142857143 \n",
      "f1: 0.6793473863010258\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayer Classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "gaussian = GaussianNB() \n",
    "gaussian.fit(X_train, y_train)  \n",
    "acc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\n",
    "print(\"train data accuracy:\",acc_gaussian)\n",
    "\n",
    "predict=gaussian.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predict))\n",
    "\n",
    "acc_gaussian = round(gaussian.score(X_test, y_test) * 100, 2)\n",
    "print(\"test data accuracy:\",acc_gaussian)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predict))\n",
    "\n",
    "\n",
    "precision=precision_score(y_test,predict,average='weighted')\n",
    "recall=recall_score(y_test,predict,average='weighted')\n",
    "f1=f1_score(y_test,predict,average='weighted')\n",
    "print(\"precision:\",precision, \"\\nrecall:\", recall, \"\\nf1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data accuracy: 62.77\n",
      "[[744 259  29   0]\n",
      " [173 516 268  90]\n",
      " [ 17 124 649 278]\n",
      " [  0  22 357 674]]\n",
      "test data accuracy: 61.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.72      0.76      1032\n",
      "           2       0.56      0.49      0.52      1047\n",
      "           3       0.50      0.61      0.55      1068\n",
      "           4       0.65      0.64      0.64      1053\n",
      "\n",
      "    accuracy                           0.61      4200\n",
      "   macro avg       0.63      0.62      0.62      4200\n",
      "weighted avg       0.62      0.61      0.62      4200\n",
      "\n",
      "precision: 0.624219790340803 \n",
      "recall: 0.615 \n",
      "f1: 0.6172230424415215\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayer Classification MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "gaussian = MultinomialNB() \n",
    "gaussian.fit(X_train, y_train)  \n",
    "acc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\n",
    "print(\"train data accuracy:\",acc_gaussian)\n",
    "\n",
    "predict=gaussian.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predict))\n",
    "\n",
    "acc_gaussian = round(gaussian.score(X_test, y_test) * 100, 2)\n",
    "print(\"test data accuracy:\",acc_gaussian)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predict))\n",
    "\n",
    "precision=precision_score(y_test,predict,average='weighted')\n",
    "recall=recall_score(y_test,predict,average='weighted')\n",
    "f1=f1_score(y_test,predict,average='weighted')\n",
    "print(\"precision:\",precision, \"\\nrecall:\", recall, \"\\nf1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM\n",
    "Classification\n",
    "Sklearn.svm\n",
    "LinearSVC()\n",
    "Sklearn.svm\n",
    "SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data accuracy: 77.35\n",
      "[[ 997   33    2    0]\n",
      " [ 225  557  263    2]\n",
      " [   0  215  715  138]\n",
      " [   0    9   43 1001]]\n",
      "test data accuracy: 77.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.97      0.88      1032\n",
      "           2       0.68      0.53      0.60      1047\n",
      "           3       0.70      0.67      0.68      1068\n",
      "           4       0.88      0.95      0.91      1053\n",
      "\n",
      "    accuracy                           0.78      4200\n",
      "   macro avg       0.77      0.78      0.77      4200\n",
      "weighted avg       0.77      0.78      0.77      4200\n",
      "\n",
      "precision: 0.7687306929141672 \n",
      "recall: 0.7785714285714286 \n",
      "f1: 0.7692698595798646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "linear_svc = LinearSVC(penalty='l1',dual=False)\n",
    "linear_svc.fit(X_train, y_train)\n",
    "acc_linear_svc = round(linear_svc.score(X_train, y_train) * 100, 2)\n",
    "print(\"train data accuracy:\",acc_linear_svc)\n",
    "\n",
    "\n",
    "predict = linear_svc.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predict))\n",
    "\n",
    "acc_linear_svc = round(linear_svc.score(X_test, y_test) * 100, 2)\n",
    "print(\"test data accuracy:\",acc_linear_svc)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predict))\n",
    "\n",
    "precision=precision_score(y_test,predict,average='weighted')\n",
    "recall=recall_score(y_test,predict,average='weighted')\n",
    "f1=f1_score(y_test,predict,average='weighted')\n",
    "print(\"precision:\",precision, \"\\nrecall:\", recall, \"\\nf1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# çœ‹é€£çºŒæ•¸å€¼+é¡žåˆ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train data: (23800, 4)\n",
      "X_test data: (4200, 4)\n"
     ]
    }
   ],
   "source": [
    "X=sampled_data[['carat', 'cut', 'color','clarity']]\n",
    "y=sampled_data['priceperpoint']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0, stratify=None) #train,target\n",
    "print(\"X_train data: \"+str(X_train.shape)) #rows and columns\n",
    "print(\"X_test data: \"+str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# çœ‹é›¢æ•£æ•¸å€¼+é¡žåˆ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train data: (23800, 4)\n",
      "X_test data: (4200, 4)\n"
     ]
    }
   ],
   "source": [
    "X=sampled_data[['carat_discrete', 'cut', 'color','clarity']]\n",
    "y=sampled_data['priceperpoint']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0, stratify=None) #train,target\n",
    "print(\"X_train data: \"+str(X_train.shape)) #rows and columns\n",
    "print(\"X_test data: \"+str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# çœ‹é€£çºŒæ•¸å€¼+äºŒå…ƒåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train data: (23800, 21)\n",
      "X_test data: (4200, 21)\n"
     ]
    }
   ],
   "source": [
    "X=sampled_data.drop(['carat_discrete', 'cut', 'color','clarity', 'priceperpoint'],axis=1)\n",
    "y=sampled_data['priceperpoint']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0, stratify=None) #train,target\n",
    "print(\"X_train data: \"+str(X_train.shape)) #rows and columns\n",
    "print(\"X_test data: \"+str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# çœ‹é›¢æ•£æ•¸å€¼+äºŒå…ƒåŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train data: (23800, 21)\n",
      "X_test data: (4200, 21)\n"
     ]
    }
   ],
   "source": [
    "X=sampled_data.drop(['carat', 'cut', 'color','clarity', 'priceperpoint'],axis=1)\n",
    "y=sampled_data['priceperpoint']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0, stratify=None) #train,target\n",
    "print(\"X_train data: \"+str(X_train.shape)) #rows and columns\n",
    "print(\"X_test data: \"+str(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data accuracy: 58.72\n",
      "[[885  94  53   0]\n",
      " [250 306 410  81]\n",
      " [  0 123 234 711]\n",
      " [  0  19  37 997]]\n",
      "test data accuracy: 57.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.78      0.86      0.82      1032\n",
      "           2       0.56      0.29      0.39      1047\n",
      "           3       0.32      0.22      0.26      1068\n",
      "           4       0.56      0.95      0.70      1053\n",
      "\n",
      "    accuracy                           0.58      4200\n",
      "   macro avg       0.56      0.58      0.54      4200\n",
      "weighted avg       0.55      0.58      0.54      4200\n",
      "\n",
      "precision: 0.5531211143853788 \n",
      "recall: 0.5766666666666667 \n",
      "f1: 0.5386573685669336\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayer Classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "gaussian = GaussianNB() \n",
    "gaussian.fit(X_train, y_train)  \n",
    "acc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\n",
    "print(\"train data accuracy:\",acc_gaussian)\n",
    "\n",
    "predict=gaussian.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predict))\n",
    "\n",
    "acc_gaussian = round(gaussian.score(X_test, y_test) * 100, 2)\n",
    "print(\"test data accuracy:\",acc_gaussian)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predict))\n",
    "\n",
    "precision=precision_score(y_test,predict,average='weighted')\n",
    "recall=recall_score(y_test,predict,average='weighted')\n",
    "f1=f1_score(y_test,predict,average='weighted')\n",
    "print(\"precision:\",precision, \"\\nrecall:\", recall, \"\\nf1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data accuracy: 54.96\n",
      "[[624 264  83  61]\n",
      " [140 430 307 170]\n",
      " [ 18 148 671 231]\n",
      " [  0 110 364 579]]\n",
      "test data accuracy: 54.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.60      0.69      1032\n",
      "           2       0.45      0.41      0.43      1047\n",
      "           3       0.47      0.63      0.54      1068\n",
      "           4       0.56      0.55      0.55      1053\n",
      "\n",
      "    accuracy                           0.55      4200\n",
      "   macro avg       0.57      0.55      0.55      4200\n",
      "weighted avg       0.57      0.55      0.55      4200\n",
      "\n",
      "precision: 0.5678498449058136 \n",
      "recall: 0.5485714285714286 \n",
      "f1: 0.5518245757486568\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayer Classification MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "gaussian = MultinomialNB() \n",
    "gaussian.fit(X_train, y_train)  \n",
    "acc_gaussian = round(gaussian.score(X_train, y_train) * 100, 2)\n",
    "print(\"train data accuracy:\",acc_gaussian)\n",
    "\n",
    "predict=gaussian.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predict))\n",
    "\n",
    "acc_gaussian = round(gaussian.score(X_test, y_test) * 100, 2)\n",
    "print(\"test data accuracy:\",acc_gaussian)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predict))\n",
    "\n",
    "precision=precision_score(y_test,predict,average='weighted')\n",
    "recall=recall_score(y_test,predict,average='weighted')\n",
    "f1=f1_score(y_test,predict,average='weighted')\n",
    "print(\"precision:\",precision, \"\\nrecall:\", recall, \"\\nf1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data accuracy: 77.69\n",
      "[[993  39   0   0]\n",
      " [247 567 232   1]\n",
      " [  0 179 666 223]\n",
      " [  1   6  47 999]]\n",
      "test data accuracy: 76.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.96      0.87      1032\n",
      "           2       0.72      0.54      0.62      1047\n",
      "           3       0.70      0.62      0.66      1068\n",
      "           4       0.82      0.95      0.88      1053\n",
      "\n",
      "    accuracy                           0.77      4200\n",
      "   macro avg       0.76      0.77      0.76      4200\n",
      "weighted avg       0.76      0.77      0.76      4200\n",
      "\n",
      "precision: 0.7593078585759271 \n",
      "recall: 0.7678571428571429 \n",
      "f1: 0.7568438591808136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "linear_svc = LinearSVC(penalty='l1',dual=False)\n",
    "linear_svc.fit(X_train, y_train)\n",
    "acc_linear_svc = round(linear_svc.score(X_train, y_train) * 100, 2)\n",
    "print(\"train data accuracy:\",acc_linear_svc)\n",
    "\n",
    "\n",
    "predict = linear_svc.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, predict))\n",
    "\n",
    "acc_linear_svc = round(linear_svc.score(X_test, y_test) * 100, 2)\n",
    "print(\"test data accuracy:\",acc_linear_svc)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,predict))\n",
    "\n",
    "precision=precision_score(y_test,predict,average='weighted')\n",
    "recall=recall_score(y_test,predict,average='weighted')\n",
    "f1=f1_score(y_test,predict,average='weighted')\n",
    "print(\"precision:\",precision, \"\\nrecall:\", recall, \"\\nf1:\", f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
